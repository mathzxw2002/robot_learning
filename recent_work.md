
# VLA




# Agent

https://dobby.now \


# LLMs

https://github.com/QwenLM/Qwen2.5-VL \

https://sebastianraschka.com/blog/2025/the-big-llm-architecture-comparison.html \

<img width="3000" height="2093" alt="image" src="https://github.com/user-attachments/assets/e56a81d3-f818-4afa-ad23-96ebbc22a6a3" />
So, in this article, rather than writing about benchmark performance or training algorithms, I will focus on the architectural developments that define todayâ€™s flagship open models.


ThinkDiff: https://mizhenxing.github.io/ThinkDiff/ \
https://github.com/MiZhenxing/ThinkDiff \
<img width="3802" height="918" alt="image" src="https://github.com/user-attachments/assets/8b088401-c3c7-4fb7-ba3d-a7ecb1257228" />


SmolLM3-3B: https://github.com/huggingface/smollm \
Everything about the SmolLM and SmolVLM family of models \
https://huggingface.co/HuggingFaceTB \


Training extremely large neural networks across thousands of GPUs. \
https://www.jeremyjordan.me/distributed-training/


Anthropic's educational courses:\
https://github.com//anthropics/courses

Reinforcement Learning from Human Feedback : \
https://rlhfbook.com \




# MCP


# Industrial Vision


PyVision: Agentic Vision with Dynamic Tooling \
paper: https://arxiv.org/pdf/2507.07998  \
homepage: https://agent-x.space/pyvision/ \
code: https://github.com/agents-x-project/PyVision \
online demo: https://huggingface.co/spaces/Agents-X/PyVision


# Course

https://ernestryu.com/courses/RL-LLM.html \


CS25: Transformers United V5: https://web.stanford.edu/class/cs25 \



# Computer Vision

Describe Anything: Detailed Localized Image and Video Captioning \
code: https://github.com/NVlabs/describe-anything \
homepage: https://describe-anything.github.io \


Master AI Agentic Engineering - build autonomous AI Agents: https://github.com/ed-donner/agents \
6 week journey to code and deploy AI Agents with OpenAI Agents SDK, CrewAI, LangGraph, AutoGen and MCP \

<img width="1536" height="1024" alt="image" src="https://github.com/user-attachments/assets/f203ec73-257e-4dd9-b538-5f33c541f175" />



Ovis-U1: Unified Understanding, Generation, and Editing: An unified model that seamlessly integrates multimodal understanding, text-to-image generation, and image editing within a single powerful framework. \
https://github.com/AIDC-AI/Ovis-U1 \
demo : https://huggingface.co/spaces/AIDC-AI/Ovis-U1-3B \


CS336: Language Modeling from Scratch
Stanford / Spring 2025: https://stanford-cs336.github.io/spring2025/

Hunyuan3D-2.1: https://github.com/Tencent-Hunyuan/Hunyuan3D-2.1 \
3d.hunyuan.tencent.com/ \



