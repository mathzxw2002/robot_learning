
1. 客户端（client.py）
1. 监听麦克风，当检测到声音（声音达到一定阈值）时开始录音，保存为 WAV 文件
2. 使用flask将音频发送给控制器（Controller）
3. 接收服务器生成并发送到客户端的语音回复音频，并播放。
2. 服务器端
2.1 控制器（app_controller.py）
客户端的所有服务都通过它协调
1. 接收音频，依次调用：
ASR 服务识别文字；
VLM 服务进行多模态推理；
TTS 服务将结果转语音；
2、将最终语音作为响应返回给客户端。
2、ASR 服务（asr_service.py）
使用 FunASR 模型，将语音转换为文字。
3、VLM 服务（vlm_service.py）
使用 Qwen2.5-VL 模型，结合图像 + ASR 文本进行推理，生成文本回复。
4、TTS 服务（tts_service.py）
使用 CosyVoice2 模型，将 VLM 生成的文本转为语音。
5、run.sh
一键启动以上所有服务。启动后会预加载模型并挂在后台，之后使用不用再重复加载模型。
